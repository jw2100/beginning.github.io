最早：找到最长的匹配词

王晓龙：最少词数的分词理论（分成数量最少的词串）


问题:二义性
	Eg：发展-中-国家  --> 发展-中国-家   北京大学生

---------------------------------------------------------------------
90 清华 郭进  统计语言模型 解决二义性：：：

假定一个句子S有几种分词,假设3个
	A1,A2,A3...Ak
	B1,B2,B3...Bm
	C1,C2,C3...Cn
	其中 A1到Cn都是汉语上的词，3个数量不同

	如果A1,A2,A3...Ak最好，那么：
	P(A1,A2,A3...Ak) > P(B1,B2,B3...Bm) && P(A1,A2,A3...Ak) > P(C1,C2,C3...Cn)

	穷举会有很大的计算量，因此使用：
		动态规划 + 维特比算法-->快速找到分词

	过程： 输入子串--->分析器([词典] [语言模型])--->输出子串
--------------------------------------------------------------------


孙茂松：没有词典的分割问题
吴德凯：中文分词用于英文，解决翻译


词语的语义不完全相同，折中办法：--->北京大学--->北京-大学(先嵌套结构)


工业界：好的统计语言模型 即可


分词一致性：不同分词器产生结果差不多，比人工分词差异小
词的颗粒度和层次：
	机器翻译中，颗粒度大，效果好

	针对不同应用，可以让相同分词器支持不同层次的分词：构造基本词表（清华、大学）和复合词表（清华大学），建立两个语言模型L1 L2
	输入语句S-->L1（使用基本词表） --->输出词串--->L2（使用复合词表）--> 输出

	分词不一致：错误和颗粒度不一致两中
		错误：越界性错误：北京大学-生
		      覆盖型错误：贾里尼可


